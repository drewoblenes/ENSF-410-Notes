## ENSF 410

## Lecture 1  (08/09/2021)

### What are we doing? 

- Python and scikit-learn for machine learning 
- Very similar to ENSF 311
- Labs will be in Monday (Optional like in ENSF 311)
- 7 labs in total (two are for review and then the other 5 are bigger)
- Labs will use both git and GitHub 
- We will be doing work in .ipynb files 
- Well get updates on Friday 
- Quizzes best 4 out of 5 

### ML introduction

In this course we will be doing very basic processes, not deep learning of neural networks. We will be exploring SUPERVISED LEARNING, and UNSUPERVISED LEARNING. 

- Supervised learning: we have a feature matrix X, and a target vector Y, the target vector is what the model should produce (testing data)
	- columns are features 
	- samples are rows 
	- Looking at Y, 
		- `Continuous data: Regression` 
		- `Discrete: Clasification`
- Unsupervised learning: We have feature matrix X, but there is not target vector Y. 
	- Dimension reduction: we are feeding in the feature matrix, and the number of features are reduced (less columns) so we are compressing the data in a meaningful way 
	- Clustering: Feature matrix X is put into a training process and the result is that we get a target matrix `Y`
		- Clustering prepares for categorization (we need to determine what classification each sample falls under) 

We will start of the term with supervised learning, then we will move onto unsupervised date.  also we will deal with special data, for example text and time data. 





